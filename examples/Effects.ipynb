{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effects Processing with audio-dsp\n",
    "\n",
    "This notebook demonstrates the audio effects available in `audio-dsp`:\n",
    "- Distortion & Saturation\n",
    "- Filters\n",
    "- Modulation (Phaser, Chorus)\n",
    "- Dynamics (Compression)\n",
    "- Spectral Effects (Vocoder)\n",
    "- Lo-Fi & Character Effects\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Metallicode/python_audio_dsp/blob/master/examples/Effects.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install audio-dsp -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## Load example .wav files to runtime (for Google Colab)\nimport os\nimport requests\n\n# Define where to save the files in Colab\noutput_dir = \"/content/assets\"\nos.makedirs(output_dir, exist_ok=True)\n\n# Define the API URL for the assets folder\napi_url = \"https://api.github.com/repos/Metallicode/python_audio_dsp/contents/examples/assets?ref=master\"\n\ntry:\n    # Get the list of files from GitHub\n    response = requests.get(api_url)\n    \n    if response.status_code == 200:\n        files = response.json()\n        print(f\"Found {len(files)} files in 'examples/assets'...\")\n        \n        # Download each file\n        for file in files:\n            if file['type'] == 'file':\n                print(f\"   Downloading {file['name']}...\")\n                raw_url = file['download_url']\n                file_content = requests.get(raw_url).content\n                \n                with open(os.path.join(output_dir, file['name']), 'wb') as f:\n                    f.write(file_content)\n        \n        print(\"\\nSuccess! Files are ready in:\", output_dir)\n        print(\"Files:\", os.listdir(output_dir))\n        \n    elif response.status_code == 404:\n        print(\"Error 404: The folder 'examples/assets' was not found.\")\n    else:\n        print(f\"GitHub API Error: {response.status_code}\")\n        \nexcept Exception as e:\n    print(f\"Download failed: {e}\")\n    print(\"Will use synthesized sounds instead.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "from audio_dsp.utils import load_audio, save_audio, normalize_audio\n",
    "from audio_dsp.synth import SubtractiveSynth\n",
    "\n",
    "SAMPLE_RATE = 44100\n",
    "\n",
    "# Visualization helpers\n",
    "def plot_waveform(audio, sr, title=\"Waveform\", figsize=(12, 3), color='#2563eb'):\n",
    "    \"\"\"Plot a waveform with time axis.\"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    time = np.arange(len(audio)) / sr\n",
    "    plt.plot(time, audio, color=color, linewidth=0.5)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Amplitude')\n",
    "    plt.title(title)\n",
    "    plt.xlim(0, time[-1])\n",
    "    plt.ylim(-1.1, 1.1)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_comparison(audio1, audio2, sr, title1=\"Original\", title2=\"Processed\", figsize=(12, 5)):\n",
    "    \"\"\"Plot two waveforms for comparison.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 1, figsize=figsize, sharex=True)\n",
    "    time1 = np.arange(len(audio1)) / sr\n",
    "    time2 = np.arange(len(audio2)) / sr\n",
    "    \n",
    "    axes[0].plot(time1, audio1, color='#2563eb', linewidth=0.5)\n",
    "    axes[0].set_ylabel('Amplitude')\n",
    "    axes[0].set_title(title1)\n",
    "    axes[0].set_ylim(-1.1, 1.1)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    axes[1].plot(time2, audio2, color='#dc2626', linewidth=0.5)\n",
    "    axes[1].set_xlabel('Time (s)')\n",
    "    axes[1].set_ylabel('Amplitude')\n",
    "    axes[1].set_title(title2)\n",
    "    axes[1].set_ylim(-1.1, 1.1)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_spectrum(audio, sr, title=\"Frequency Spectrum\", figsize=(12, 3)):\n",
    "    \"\"\"Plot the frequency spectrum.\"\"\"\n",
    "    n = len(audio)\n",
    "    fft = np.abs(np.fft.rfft(audio))\n",
    "    freqs = np.fft.rfftfreq(n, 1/sr)\n",
    "    fft_db = 20 * np.log10(fft + 1e-10)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.plot(freqs, fft_db, color='#2563eb', linewidth=0.5)\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Magnitude (dB)')\n",
    "    plt.title(title)\n",
    "    plt.xlim(20, 15000)\n",
    "    plt.xscale('log')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Test Sounds\n\nWe'll try to load audio files first. If not available, we'll create synthesized test sounds."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Try to load audio files first, fall back to synthesis\nimport os\n\n# Check for Colab or local paths\nif os.path.exists(\"/content/assets\"):\n    assets_dir = \"/content/assets\"\nelif os.path.exists(\"assets\"):\n    assets_dir = \"assets\"\nelse:\n    assets_dir = None\n\nloaded_files = False\n\nif assets_dir:\n    try:\n        # load_audio returns (sr, audio) - must unpack!\n        guitar_path = os.path.join(assets_dir, \"guitar.wav\")\n        drums_path = os.path.join(assets_dir, \"drums.wav\")\n        synth_path = os.path.join(assets_dir, \"synth.wav\")\n        \n        if os.path.exists(guitar_path):\n            _, guitar = load_audio(guitar_path)\n            print(f\"Loaded guitar: {len(guitar)/SAMPLE_RATE:.2f}s\")\n            loaded_files = True\n        \n        if os.path.exists(drums_path):\n            _, drums = load_audio(drums_path)\n            print(f\"Loaded drums: {len(drums)/SAMPLE_RATE:.2f}s\")\n        \n        if os.path.exists(synth_path):\n            _, synth_pad = load_audio(synth_path)\n            print(f\"Loaded synth: {len(synth_pad)/SAMPLE_RATE:.2f}s\")\n            \n    except Exception as e:\n        print(f\"Error loading files: {e}\")\n        loaded_files = False\n\n# Fall back to synthesized sounds if files not loaded\nif not loaded_files:\n    print(\"Creating synthesized test sounds...\")\n    \n    synth = SubtractiveSynth(sample_rate=SAMPLE_RATE)\n    \n    # Guitar-like sound\n    synth.osc_wave = \"saw\"\n    synth.filter_cutoff = 2000\n    synth.filter_resonance = 1.5\n    synth.attack = 0.01\n    synth.decay = 0.3\n    synth.sustain = 0.5\n    synth.release = 0.3\n    \n    guitar = np.concatenate([\n        synth.synthesize(110, 0.5),\n        synth.synthesize(146.8, 0.5),\n        synth.synthesize(110, 0.5),\n        synth.synthesize(164.8, 0.5)\n    ])\n    \n    # Drum-like sound\n    from audio_dsp.synth.chip_tone import generate_kick, generate_snare, generate_cymbal\n    \n    step_len = int(SAMPLE_RATE * 0.125)\n    def pad_sound(sound, length):\n        if len(sound) >= length:\n            return sound[:length]\n        return np.pad(sound, (0, length - len(sound)))\n    \n    drums = []\n    for i in range(16):\n        step = np.zeros(step_len)\n        if i in [0, 8]: step += pad_sound(generate_kick(), step_len)\n        if i in [4, 12]: step += pad_sound(generate_snare(), step_len)\n        if i % 2 == 0: step += pad_sound(generate_cymbal(), step_len) * 0.3\n        drums.append(step)\n    drums = np.clip(np.concatenate(drums), -1, 1)\n    \n    # Synth pad\n    synth.osc_wave = \"triangle\"\n    synth.filter_cutoff = 1500\n    synth.attack = 0.2\n    synth.release = 0.5\n    synth_pad = synth.synthesize(220, 2.0)\n    \n    print(f\"  Guitar: {len(guitar)/SAMPLE_RATE:.2f}s\")\n    print(f\"  Drums: {len(drums)/SAMPLE_RATE:.2f}s\")\n    print(f\"  Synth: {len(synth_pad)/SAMPLE_RATE:.2f}s\")\n\nprint(\"\\nTest sounds ready!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Distortion & Saturation\n",
    "\n",
    "19 different distortion types from subtle warmth to extreme destruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_dsp.effects import (\n",
    "    fuzz_distortion,\n",
    "    overdrive_distortion,\n",
    "    saturation_distortion,\n",
    "    wavefold_distortion,\n",
    "    bitcrush_distortion\n",
    ")\n",
    "\n",
    "print(\"Original:\")\n",
    "plot_waveform(guitar, SAMPLE_RATE, \"Original\")\n",
    "display(Audio(guitar, rate=SAMPLE_RATE))\n",
    "\n",
    "# Subtle saturation\n",
    "saturated = saturation_distortion(guitar, gain=1.5, threshold=0.7, mix=0.7)\n",
    "print(\"\\nSaturation (subtle warmth):\")\n",
    "plot_comparison(guitar, saturated, SAMPLE_RATE, \"Original\", \"Saturation\")\n",
    "display(Audio(saturated, rate=SAMPLE_RATE))\n",
    "\n",
    "# Overdrive\n",
    "overdriven = overdrive_distortion(guitar, gain=3.0, threshold=0.5, mix=0.8)\n",
    "print(\"\\nOverdrive (tube-style):\")\n",
    "plot_comparison(guitar, overdriven, SAMPLE_RATE, \"Original\", \"Overdrive\")\n",
    "display(Audio(overdriven, rate=SAMPLE_RATE))\n",
    "\n",
    "# Heavy fuzz\n",
    "fuzzed = fuzz_distortion(guitar, gain=12.0, threshold=0.2, mix=0.9)\n",
    "print(\"\\nFuzz (extreme):\")\n",
    "plot_comparison(guitar, fuzzed, SAMPLE_RATE, \"Original\", \"Fuzz\")\n",
    "display(Audio(fuzzed, rate=SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavefold distortion - great for synths\n",
    "print(\"Original synth:\")\n",
    "display(Audio(synth_pad, rate=SAMPLE_RATE))\n",
    "\n",
    "folded = wavefold_distortion(synth_pad, gain=5.0, mix=0.8)\n",
    "print(\"\\nWavefold (harmonic richness):\")\n",
    "plot_comparison(synth_pad, folded, SAMPLE_RATE, \"Original\", \"Wavefold\")\n",
    "display(Audio(folded, rate=SAMPLE_RATE))\n",
    "\n",
    "# Bitcrush for lo-fi\n",
    "crushed = bitcrush_distortion(synth_pad, bits=6, mix=1.0)\n",
    "print(\"\\nBitcrush (6-bit):\")\n",
    "plot_comparison(synth_pad, crushed, SAMPLE_RATE, \"Original\", \"Bitcrush\")\n",
    "display(Audio(crushed, rate=SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filters\n",
    "\n",
    "Resonant ladder-style filters with analog character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_dsp.effects import filter_effect\n",
    "\n",
    "print(\"Original drums:\")\n",
    "display(Audio(drums, rate=SAMPLE_RATE))\n",
    "\n",
    "# Low-pass filter\n",
    "lp_filtered = filter_effect(drums, SAMPLE_RATE, cutoff=500, resonance=2.0, filter_type=\"lowpass\")\n",
    "print(\"\\nLow-pass (500 Hz, resonance=2):\")\n",
    "plot_comparison(drums, lp_filtered, SAMPLE_RATE, \"Original\", \"Low-pass 500Hz\")\n",
    "display(Audio(lp_filtered, rate=SAMPLE_RATE))\n",
    "\n",
    "# High resonance for acid-style sound\n",
    "acid = filter_effect(drums, SAMPLE_RATE, cutoff=800, resonance=4.5, filter_type=\"lowpass\")\n",
    "print(\"\\nAcid-style (800 Hz, high resonance):\")\n",
    "plot_comparison(drums, acid, SAMPLE_RATE, \"Original\", \"Acid Filter\")\n",
    "display(Audio(acid, rate=SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter sweep visualization\n",
    "# Create a rich synth to filter\n",
    "synth.osc_wave = \"saw\"\n",
    "synth.filter_cutoff = 8000\n",
    "sweep_source = synth.synthesize(110, 3.0)\n",
    "\n",
    "# Process in chunks with changing cutoff\n",
    "chunk_size = int(SAMPLE_RATE * 0.03)\n",
    "n_chunks = len(sweep_source) // chunk_size\n",
    "\n",
    "swept = []\n",
    "cutoffs = []\n",
    "for i in range(n_chunks):\n",
    "    chunk = sweep_source[i*chunk_size:(i+1)*chunk_size]\n",
    "    # Sweep cutoff from 200 to 4000 Hz and back\n",
    "    progress = i / n_chunks\n",
    "    cutoff = 200 + 3800 * np.sin(progress * np.pi)\n",
    "    cutoffs.append(cutoff)\n",
    "    filtered_chunk = filter_effect(chunk, SAMPLE_RATE, cutoff=cutoff, resonance=3.0)\n",
    "    swept.append(filtered_chunk)\n",
    "\n",
    "swept = np.concatenate(swept)\n",
    "\n",
    "# Plot the sweep\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 6))\n",
    "\n",
    "time = np.arange(len(swept)) / SAMPLE_RATE\n",
    "axes[0].plot(time, swept, color='#2563eb', linewidth=0.3)\n",
    "axes[0].set_ylabel('Amplitude')\n",
    "axes[0].set_title('Filter Sweep Waveform')\n",
    "axes[0].set_ylim(-1.1, 1.1)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "cutoff_time = np.linspace(0, len(swept)/SAMPLE_RATE, len(cutoffs))\n",
    "axes[1].plot(cutoff_time, cutoffs, color='#dc2626', linewidth=2)\n",
    "axes[1].set_xlabel('Time (s)')\n",
    "axes[1].set_ylabel('Cutoff (Hz)')\n",
    "axes[1].set_title('Filter Cutoff Automation')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Filter sweep (200 Hz -> 4000 Hz -> 200 Hz):\")\n",
    "Audio(swept, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vocoder\n",
    "\n",
    "Classic vocoder effect for robotic voice sounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_dsp.effects.vocoder import vocoder\n",
    "from audio_dsp.utils import white_noise\n",
    "\n",
    "# Create a modulator (speech-like: amplitude-modulated noise)\n",
    "duration = 2.0\n",
    "t = np.linspace(0, duration, int(duration * SAMPLE_RATE))\n",
    "\n",
    "# Simulate speech-like modulation\n",
    "modulation = np.abs(np.sin(2 * np.pi * 3 * t)) * np.abs(np.sin(2 * np.pi * 0.5 * t))\n",
    "noise_mod = white_noise(len(t)) * modulation * 0.5\n",
    "noise_mod = filter_effect(noise_mod, SAMPLE_RATE, cutoff=3000, resonance=1.0)\n",
    "\n",
    "# Create carrier (synth pad)\n",
    "synth.osc_wave = \"saw\"\n",
    "synth.filter_cutoff = 5000\n",
    "carrier = synth.synthesize(110, duration)\n",
    "\n",
    "print(\"Carrier (synth):\")\n",
    "display(Audio(carrier, rate=SAMPLE_RATE))\n",
    "\n",
    "print(\"\\nModulator (noise):\")\n",
    "display(Audio(noise_mod, rate=SAMPLE_RATE))\n",
    "\n",
    "# Apply vocoder\n",
    "vocoded, _ = vocoder(\n",
    "    carrier=carrier,\n",
    "    modulator=noise_mod,\n",
    "    sr=SAMPLE_RATE,\n",
    "    n_filters=32,\n",
    "    freq_range=(80, 8000)\n",
    ")\n",
    "\n",
    "print(\"\\nVocoded output:\")\n",
    "plot_comparison(carrier, vocoded, SAMPLE_RATE, \"Carrier\", \"Vocoded\")\n",
    "Audio(vocoded, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robot voice with generated sawtooth carrier\n",
    "robot_voice, _ = vocoder(\n",
    "    carrier=None,  # Generate carrier\n",
    "    modulator=noise_mod,\n",
    "    sr=SAMPLE_RATE,\n",
    "    carrier_type=\"sawtooth\",\n",
    "    carrier_freq=110,\n",
    "    n_filters=48\n",
    ")\n",
    "\n",
    "plot_waveform(robot_voice, SAMPLE_RATE, \"Robot Voice (Generated Sawtooth Carrier)\")\n",
    "\n",
    "print(\"Robot voice (sawtooth carrier @ 110 Hz):\")\n",
    "Audio(robot_voice, rate=SAMPLE_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modulation Effects\n",
    "\n",
    "Pitch modulation effects for movement and character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from audio_dsp.effects import flutter_effect, pitch_drift, tape_saturation\n\n# Pitch flutter (vibrato/wow effect)\nfluttered = flutter_effect(\n    guitar,\n    sample_rate=SAMPLE_RATE,\n    base_rate=5.0,\n    rate_diff=1.0,\n    depth=0.02\n)\nprint(\"Pitch flutter (vibrato):\")\nplot_comparison(guitar, fluttered, SAMPLE_RATE, \"Original\", \"Flutter\")\ndisplay(Audio(fluttered, rate=SAMPLE_RATE))\n\n# Pitch drift (slow random detuning)\ndrifted = pitch_drift(\n    guitar,\n    sample_rate=SAMPLE_RATE,\n    drift_depth=0.3,\n    drift_rate=0.05\n)\nprint(\"\\nPitch drift (tape-like):\")\nplot_comparison(guitar, drifted, SAMPLE_RATE, \"Original\", \"Drift\")\ndisplay(Audio(drifted, rate=SAMPLE_RATE))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Tape saturation\ntaped = tape_saturation(\n    guitar,\n    sample_rate=SAMPLE_RATE,\n    drive=2.0,\n    warmth=0.7,\n    output_level=1.0\n)\n\nprint(\"Tape saturation:\")\nplot_comparison(guitar, taped, SAMPLE_RATE, \"Original\", \"Tape Saturation\")\nAudio(taped, rate=SAMPLE_RATE)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Multi-Band Processing\n",
    "\n",
    "Split audio into frequency bands and process independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audio_dsp.effects.multi_band_saturation import process_multi_band\n",
    "\n",
    "# 3-band saturation: warm lows, crunchy mids, clean highs\n",
    "multiband = process_multi_band(\n",
    "    drums,\n",
    "    fs=SAMPLE_RATE,\n",
    "    crossovers=[200, 2000],\n",
    "    drives=[2.0, 4.0, 1.0]\n",
    ")\n",
    "\n",
    "print(\"Multi-band saturation (warm lows, crunchy mids, clean highs):\")\n",
    "plot_comparison(drums, multiband, SAMPLE_RATE, \"Original Drums\", \"Multi-band Saturated\")\n",
    "\n",
    "# Show spectrum comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "for i, (audio, title) in enumerate([(drums, \"Original\"), (multiband, \"Multi-band\")]):\n",
    "    fft = np.abs(np.fft.rfft(audio))\n",
    "    freqs = np.fft.rfftfreq(len(audio), 1/SAMPLE_RATE)\n",
    "    fft_db = 20 * np.log10(fft + 1e-10)\n",
    "    axes[i].plot(freqs, fft_db, linewidth=0.5)\n",
    "    axes[i].set_xlabel('Frequency (Hz)')\n",
    "    axes[i].set_ylabel('Magnitude (dB)')\n",
    "    axes[i].set_title(f'{title} Spectrum')\n",
    "    axes[i].set_xlim(20, 15000)\n",
    "    axes[i].set_xscale('log')\n",
    "    axes[i].axvline(200, color='r', linestyle='--', alpha=0.5, label='Crossover')\n",
    "    axes[i].axvline(2000, color='r', linestyle='--', alpha=0.5)\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "display(Audio(drums, rate=SAMPLE_RATE))\n",
    "print(\"\\nMulti-band:\")\n",
    "display(Audio(multiband, rate=SAMPLE_RATE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Effect Chains\n",
    "\n",
    "Combine multiple effects for complex sound design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Guitar pedalboard simulation\nsignal = guitar.copy()\nchain_stages = [('Original', signal.copy())]\n\n# 1. Overdrive\nsignal = overdrive_distortion(signal, gain=2.5, threshold=0.6, mix=0.7)\nchain_stages.append(('+ Overdrive', signal.copy()))\n\n# 2. Filter (tone control)\nsignal = filter_effect(signal, SAMPLE_RATE, cutoff=3000, resonance=1.0)\nchain_stages.append(('+ Filter', signal.copy()))\n\n# 3. Tape saturation for warmth\nsignal = tape_saturation(signal, sample_rate=SAMPLE_RATE, drive=1.5, warmth=0.5, output_level=1.0)\nchain_stages.append(('+ Tape', signal.copy()))\n\n# 4. Normalize\nsignal = normalize_audio(signal, peak=0.9)\n\n# Visualize the chain\nfig, axes = plt.subplots(len(chain_stages), 1, figsize=(12, 10))\n\nfor i, (name, audio) in enumerate(chain_stages):\n    time = np.arange(len(audio)) / SAMPLE_RATE\n    axes[i].plot(time, audio, color='#2563eb', linewidth=0.5)\n    axes[i].set_ylabel(name)\n    axes[i].set_ylim(-1.1, 1.1)\n    axes[i].grid(True, alpha=0.3)\n\naxes[-1].set_xlabel('Time (s)')\nplt.suptitle('Effect Chain Visualization')\nplt.tight_layout()\nplt.show()\n\nprint(\"Original:\")\ndisplay(Audio(guitar, rate=SAMPLE_RATE))\n\nprint(\"\\nFinal (Overdrive -> Filter -> Tape):\")\ndisplay(Audio(signal, rate=SAMPLE_RATE))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Experimental synth processing\nsignal = synth_pad.copy()\n\n# 1. Wavefold for harmonics\nsignal = wavefold_distortion(signal, gain=3.0, mix=0.6)\n\n# 2. Bitcrush for digital grit\nsignal = bitcrush_distortion(signal, bits=10, mix=0.3)\n\n# 3. Resonant filter\nsignal = filter_effect(signal, SAMPLE_RATE, cutoff=1500, resonance=3.5)\n\n# 4. Pitch flutter for movement\nsignal = flutter_effect(signal, sample_rate=SAMPLE_RATE, base_rate=3.0, depth=0.01)\n\nsignal = normalize_audio(signal, peak=0.9)\n\nplot_comparison(synth_pad, signal, SAMPLE_RATE, \"Original Synth\", \"Experimental Chain\")\n\nprint(\"Original synth:\")\ndisplay(Audio(synth_pad, rate=SAMPLE_RATE))\n\nprint(\"\\nExperimental (Wavefold -> Bitcrush -> Filter -> Flutter):\")\ndisplay(Audio(signal, rate=SAMPLE_RATE))"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Saving Processed Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_audio(\"output_effects.wav\", signal, SAMPLE_RATE)\n",
    "print(\"Saved to output_effects.wav\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}